{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPj76X_FP2uq"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Run the code below to load the scrambled message:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YwkYMR2qP2ur"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "message = pd.read_csv(\"https://www.dropbox.com/s/lgpn3vmksk3ssdo/scrambled_message.txt?dl=1\")['Word']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqykaCOxF1Z9",
        "outputId": "78651d97-c46b-4c24-b5e9-f67ae6a0ea1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                    Koila!\n",
              "1                     In   \n",
              "2                     kiew,\n",
              "3                         a\n",
              "4                 humble   \n",
              "               ...         \n",
              "122                     you\n",
              "123                 mabugh.\n",
              "124              ughhh?call\n",
              "125        meugh.ughhhh!   \n",
              "126                      K.\n",
              "Name: Word, Length: 127, dtype: object"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI8ZE3LAP2us"
      },
      "source": [
        "In this activity, a \"word\" refers to any set of characters with no white space, even though they are not truly an English word.  That is, even though many of elements of the scrambled message vector are nonsense, and some have punctuation, you can consider each element to be a \"word\".\n",
        "\n",
        "Beware!  The object named `message` is a **pandas Series** of strings.  If you want to use functions that expect a string, rather than a series, remember `.apply()` and `lambda` functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYISAD8uQLAy"
      },
      "source": [
        "\n",
        "## Warm-up exercises\n",
        "\n",
        "1. How many characters are in the scrambled message?\n",
        "2. How many of these characters are white space?\n",
        "3. How many words are in the scrambled message?\n",
        "4. Show all the punctuation marks in the scrambled message.\n",
        "5. Print out, in all capitals, the longest word in the scrambled message.\n",
        "6. Print out every piece of a word that starts with the letter \"m\" and ends with the letter \"z\" in the scrambled message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6vB1tbjiQNvE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2544"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#1\n",
        "message.str.len().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#2\n",
        "whitespace_count = message.apply(lambda word: word.count(' ')).sum()\n",
        "whitespace_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#3\n",
        "word_count = len(message)\n",
        "word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'.', ',', '!', '?', ';'}\n",
            "{'.', ',', '!', '?', ';'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#4\n",
        "import re\n",
        "punctuation_marks = message.apply(lambda word: re.findall(r'[^\\w\\s]', word))\n",
        "#used ChatGPT for help with this part\n",
        "unique_punctuation = set([p for sublist in punctuation_marks for p in sublist])\n",
        "print(unique_punctuation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'KAUDEVILLIANUGH?AOGHAJDBN'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#5\n",
        "#ChatGPT helped me with this part too (idxmax())\n",
        "longest_word = message.apply(len).idxmax()\n",
        "longest_word_in_caps = message[longest_word].upper()\n",
        "longest_word_in_caps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['maaz']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#6\n",
        "#split each word by punctuation marks and then check if any pieces start with 'm' and end with 'z'\n",
        "matching_words_with_split = message.apply(lambda word: re.findall(r'\\bm\\w*z\\b', re.sub(r'[^\\w\\s]', ' ', word)))\n",
        "matching_words_list = [word for sublist in matching_words_with_split for word in sublist]\n",
        "matching_words_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iJnnCJQOh7"
      },
      "source": [
        "\n",
        "\n",
        "## Decode a message\n",
        "\n",
        "Complete the following steps to decode the message.  \n",
        "\n",
        "1. Remove any spaces before or after each word.\n",
        "2. Any time you see the word \"ugh\", with any number of h's, followed by a punctuation mark, delete this.\n",
        "3. No word should be longer than 16 characters. Drop all extra characters beyond 13 off the end of each word.\n",
        "4. Replace all instances of exactly 2 a's with exactly 2 e's.\n",
        "5. Replace all z's with t's.\n",
        "6. Every word that ends in b, change that to a y.  *Hint: look out for punctuation!*\n",
        "7. Every word that starts with k, change that to a v.  *Hint: look out for capitalization!*\n",
        "8. Use `.join()` to recombine all your words into a message.\n",
        "9. Find the movie this quote is from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RRfjUzxMQQ5j"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Voila! In view, a humble vaudevillianu veteran, cast vicariously as both victim and villain by the vicissitudes of fate. This visage, no mereugh? veneer ofugh? vanity, is a vestige of the vox populi now vacant, vanished.ugh? However, this valorous visitation of a bygone vexation stands vivified, and hasugh. vowed to vanquish these venalugh? and virulent vermin, van guarding viceugh. and vouchsafingugh? the violently vicious and voraciousugh? violation of volition.ugh? Theugh. only verdict isugh. vengeance; a vendetta, held as a votive not in vain, forugh. the value andugh? veracity ofugh. such shall one dabugh. vindicate the vigilant and the virtuous. Verily this vichyssoise of verbiage veers mostugh? verbose, so let me simply add that its my very good honourugh. to meet you and you mabugh. call meugh. V.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#1\n",
        "message_cleaned = message.apply(lambda word: word.strip())\n",
        "\n",
        "#2\n",
        "message_cleaned = message_cleaned.apply(lambda word: re.sub(r'ugh+h+[.,!?;]', '', word))\n",
        "\n",
        "#3\n",
        "message_cleaned = message_cleaned.apply(lambda word: word[:13] if len(word) > 16 else word)\n",
        "\n",
        "#4\n",
        "message_cleaned = message_cleaned.apply(lambda word: re.sub(r'aa', 'ee', word))\n",
        "\n",
        "#5\n",
        "message_cleaned = message_cleaned.apply(lambda word: word.replace('z', 't'))\n",
        "\n",
        "#6\n",
        "message_cleaned = message_cleaned.apply(lambda word: re.sub(r'b\\b', 'y', word))\n",
        "\n",
        "#7\n",
        "message_cleaned = message_cleaned.apply(lambda word: re.sub(r'\\bK', 'V', word)).apply(lambda word: re.sub(r'\\bk', 'v', word))\n",
        "\n",
        "#8\n",
        "decoded_message = ' '.join(message_cleaned)\n",
        "\n",
        "decoded_message"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
